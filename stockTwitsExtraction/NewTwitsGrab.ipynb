{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pandas.io.json import json_normalize\n",
    "import os\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stock Symbols that we will iterate through\n",
    "# Apple = AAPL\n",
    "# Amazon = AMZN\n",
    "# Google = GOOGL\n",
    "# Microsoft = MSFT\n",
    "# Dell = DELL\n",
    "# IBM = IBM\n",
    "# Intel = INTC\n",
    "# HP = HPQ\n",
    "# Facebook = FB\n",
    "# Cisco Systems = CSCO\n",
    "# Oracle = ORCL\n",
    "# HP Enterprise = HPE\n",
    "# Micron Tech = MU\n",
    "# DXC Tech = DXC\n",
    "# Thermo Fisher Scientific = TMO\n",
    "\n",
    "# Qualcomm = QCOM\n",
    "# Jabil = JBL\n",
    "# Broadcom = AVGO\n",
    "# Western Digital = WDC\n",
    "# Applied Materials = AMAT\n",
    "\n",
    "\n",
    "# Tesla = TSLA\n",
    "# Alibaba = BABA\n",
    "# Nvidia = NVDA\n",
    "# Walmart = WMT\n",
    "# Walt Disney = DIS\n",
    "stockSymbol = [\"AAPL\", \"AMZN\", \"GOOGL\",\"MSFT\", \"DELL\", \"IBM\", \"INTC\", \"HPQ\",\n",
    "               \"FB\", \"CSCO\", \"ORCL\", \"HPE\", \"MU\", \"DXC\", \"TMO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathers the json file and all needed data values.\n",
    "def collect_Twits(res):\n",
    "    try:\n",
    "        df = (json_normalize(res['messages'])[{'id','body','created_at','entities.sentiment.basic','symbols'}])\n",
    "        \n",
    "        #Reorders the columns\n",
    "        df = df[['id','body','created_at','entities.sentiment.basic','symbols']]\n",
    "        \n",
    "        #Renames the columns\n",
    "        df = df.rename(columns = {'created_at':'created', 'entities.sentiment.basic': 'tag'})\n",
    "        \n",
    "    except:\n",
    "        df = (json_normalize(res['messages'])[{'id','body','created_at','entities.sentiment','symbols'}])\n",
    "        #Reorders the columns\n",
    "        df = df[['id','body','created_at','entities.sentiment','symbols']]\n",
    "        \n",
    "        #Renames the columns\n",
    "        df = df.rename(columns = {'created_at':'created', 'entities.sentiment': 'tag'})\n",
    "\n",
    "\n",
    "    #Replaces the NAN with a string \"none\"\n",
    "    df = df.replace(np.nan, 'none', regex=True)\n",
    "    \n",
    "    #Replaces the string as a datetime variable\n",
    "    dateFormat = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    df['created'] = pd.to_datetime(df['created'], format=dateFormat)\n",
    "    \n",
    "    #returns the dataframe in correct format\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathers the json file and all needed data values.\n",
    "def collect_New_Twits(res):\n",
    "    try:\n",
    "        df = (json_normalize(res['messages'])[{'id','body','created_at','entities.sentiment.basic','symbols'}])\n",
    "        \n",
    "        #Reorders the columns\n",
    "        df = df[['id','body','created_at','entities.sentiment.basic','symbols']]\n",
    "        \n",
    "        #Renames the columns\n",
    "        df = df.rename(columns = {'created_at':'created', 'entities.sentiment.basic': 'tag'})\n",
    "        \n",
    "    except:\n",
    "        df = (json_normalize(res['messages'])[{'id','body','created_at','entities.sentiment','symbols'}])\n",
    "        #Reorders the columns\n",
    "        df = df[['id','body','created_at','entities.sentiment','symbols']]\n",
    "        \n",
    "        #Renames the columns\n",
    "        df = df.rename(columns = {'created_at':'created', 'entities.sentiment': 'tag'})\n",
    "\n",
    "\n",
    "    #Replaces the NAN with a string \"none\"\n",
    "    df = df.replace(np.nan, 'none', regex=True)\n",
    "    \n",
    "    #Replaces the string as a datetime variable\n",
    "    dateFormat = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    df['created'] = pd.to_datetime(df['created'], format=dateFormat)\n",
    "    \n",
    "    #Newest posts will be on top\n",
    "    df.sort_values('created', ascending=False)\n",
    "    \n",
    "    #returns the dataframe in correct format\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    for symbol in stockSymbol:\n",
    "    \n",
    "        #selects the file to add to\n",
    "        file = '{}_newTwits.csv'.format(symbol)\n",
    "    \n",
    "        historicalTwits = pd.read_csv(file)\n",
    "        newestID = historicalTwits['id'].iloc[0]\n",
    "    \n",
    "        url = \"https://api.stocktwits.com/api/2/streams/symbol/{}.json\".format(symbol)\n",
    "        response = requests.get(url, params = {'since' :  newestID}).json()\n",
    "    \n",
    "        tempNewTwitsDf = collect_New_Twits(response)\n",
    "\n",
    "        newHistoricalTwits = tempTwitsDf.append(historicalTwits)\n",
    "    \n",
    "        newHistoricalTwits.to_csv(r'{}_newTwits.csv'.format(symbol), index=False)\n",
    "        time.sleep(30)\n",
    "        newHistoricalTwits.to_csv(r'{}_newTwitsCopy.csv'.format(symbol), index=False)\n",
    "        time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
